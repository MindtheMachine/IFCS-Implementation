LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434

# ===== MODEL CONFIG =====
LLM_MODEL=mistral:7b-instruct-q4_K_M

# ===== GENERATION PARAMS =====
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.9
LLM_MAX_TOKENS=512

# ===== TIMEOUTS =====
LLM_TIMEOUT=120
