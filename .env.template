# ============================================================================
# Trilogy System - Environment Configuration Template
# ============================================================================
# INSTRUCTIONS:
# 1. Copy this file to .env: copy .env.template .env
# 2. Uncomment ONE provider section below
# 3. Add your API key
# 4. Save and run: python trilogy_app.py --prompt "Hello"
#
# ============================================================================

# ============================================================================
# OPTION 1: Anthropic Claude (Recommended - Best Quality)
# ============================================================================
# Get API key from: https://console.anthropic.com/
# Cost: ~$5-10 for full TruthfulQA benchmark
#
LLM_PROVIDER=anthropic
LLM_MODEL=claude-sonnet-4-20250514
LLM_API_KEY=your-anthropic-api-key-here
# Example: LLM_API_KEY=sk-ant-api03-AbCdEfGhIjKlMnOpQrStUvWxYz1234567890

# ============================================================================
# OPTION 2: OpenAI GPT-4 (Excellent Quality)
# ============================================================================
# Get API key from: https://platform.openai.com/
# Cost: ~$8-15 for full TruthfulQA benchmark
#
# LLM_PROVIDER=openai
# LLM_MODEL=gpt-4-turbo
# LLM_API_KEY=your-openai-api-key-here
# Example: LLM_API_KEY=sk-proj-AbCdEfGhIjKlMnOpQrStUvWxYz1234567890
#
# Other OpenAI models:
# LLM_MODEL=gpt-4o              # Multimodal, fast
# LLM_MODEL=gpt-3.5-turbo       # Cheaper ($1-3 for benchmark)

# ============================================================================
# OPTION 3: HuggingFace Inference API (FREE TIER AVAILABLE!)
# ============================================================================
# Get FREE token from: https://huggingface.co/settings/tokens
# Cost: FREE (with rate limits) or $0.65/1M tokens (Pro)
#
# LLM_PROVIDER=huggingface
# LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct
# LLM_API_KEY=your-huggingface-token-here
# Example: LLM_API_KEY=hf_AbCdEfGhIjKlMnOpQrStUvWxYz
#
# Recommended FREE tier models:
# LLM_MODEL=meta-llama/Llama-3.1-8B-Instruct   # Fast, good quality
# LLM_MODEL=mistralai/Mistral-7B-Instruct-v0.3 # Very efficient
# LLM_MODEL=google/gemma-2-9b-it               # Recent, reliable
# LLM_MODEL=Qwen/Qwen2.5-7B-Instruct           # Excellent quality
#
# For FREE tier, use smaller batches and rate limiting:
# python trilogy_app.py --benchmark truthfulqa --batch-size 5 --rate-limit 2.0

# ============================================================================
# OPTION 4: Ollama (Local - 100% FREE, No API Key Needed!)
# ============================================================================
# Download from: https://ollama.com/
# Setup: ollama pull llama3.1
# Cost: $0 (completely free, runs on your machine)
#
# LLM_PROVIDER=ollama
# LLM_MODEL=llama3.1
# No LLM_API_KEY needed!
#
# Recommended local models:
# LLM_MODEL=llama3.1           # 8B - Best quality/speed balance (4.7GB)
# LLM_MODEL=phi3               # 3.8B - Very fast, small (2.3GB)
# LLM_MODEL=mistral            # 7B - Efficient (4.1GB)
# LLM_MODEL=qwen2.5            # 7B - Excellent quality (4.7GB)
#
# OLLAMA_BASE_URL=http://localhost:11434  # Default Ollama server
# ===== LLM BACKEND =====
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434

# ===== MODEL CONFIG =====
OLLAMA_MODEL=mistral:7b-instruct-q4_K_M

# ===== GENERATION PARAMS =====
LLM_TEMPERATURE=0.7
LLM_TOP_P=0.9
LLM_MAX_TOKENS=512

# ===== TIMEOUTS =====
LLM_TIMEOUT=120


# ============================================================================
# Legacy Configuration (Backward Compatibility)
# ============================================================================
# Old .env files used ANTHROPIC_API_KEY directly
# Still supported - will be used if LLM_API_KEY not set
# ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ============================================================================
# IFCS (Inference-Time Commitment Shaping) Configuration
# ============================================================================
# Reference: IFCS paper Table 1, Section 4.3.1
# See: Documentation/CONFIGURATION.md for detailed guide
#
# QUICK START: Set domain for automatic preset
# IFCS_DOMAIN=default         # Standard (ρ=0.40)
# IFCS_DOMAIN=medical         # Strict (ρ=0.30) - for health advice
# IFCS_DOMAIN=legal           # Strict (ρ=0.30) - for legal queries
# IFCS_DOMAIN=financial       # Moderate (ρ=0.35) - for finance
#
# OR manually configure individual parameters:
#
# IFCS_RHO: Commitment risk threshold (0.0-1.0)
#   Lower = more interventions (stricter)
#   Higher = fewer interventions (more permissive)
#   Defaults: medical/legal=0.30, financial=0.35, default=0.40
# IFCS_RHO=0.40
#
# IFCS_LAMBDA_E: Evidential risk weight (0.0-1.0)
#   Weight for evidential sufficiency component
#   Higher = emphasize grounding/evidence
# IFCS_LAMBDA_E=0.40
#
# IFCS_LAMBDA_S: Scope inflation weight (0.0-1.0)
#   Weight for scope/generalization component
# IFCS_LAMBDA_S=0.30
#
# IFCS_LAMBDA_A: Authority cues weight (0.0-1.0)
#   Weight for authority/directive language
# IFCS_LAMBDA_A=0.30
#
# IFCS_LAMBDA_T: Temporal risk weight (0.0-1.0)
#   Weight for temporal grounding (optional, usually 0.0)
# IFCS_LAMBDA_T=0.00
#
# NOTE: All lambda weights must sum to 1.0

# ============================================================================
# ECR (Evaluative Coherence Regulation) Configuration
# ============================================================================
# ECR_K: Number of candidate responses to generate (3-5 recommended)
# ECR_K=5
#
# ECR_H: Inference horizon (number of steps, 2-4 recommended)
# ECR_H=3
#
# ECR_TAU_CCI: Composite Coherence Index threshold (0.0-1.0)
#   Default: 0.65
#   Target: Admit 70-80% of trajectories
# ECR_TAU_CCI=0.65

# ============================================================================
# Control Probe Configuration
# ============================================================================
# CP_TAU: Type-1 admissibility threshold (0.0-1.0)
#   Minimum evaluative support for commitment
#   Default: 0.40
# CP_TAU=0.40
#
# CP_THETA: Type-2 cumulative risk threshold (0.5-3.0)
#   Cumulative risk across interaction history
#   Default: 2.0
# CP_THETA=2.0

# ============================================================================
# Quick Test Commands
# ============================================================================
# After setup, test with:
#
# Single query:
#   python trilogy_app.py --prompt "What is quantum computing?"
#
# Small benchmark (recommended first test):
#   python trilogy_app.py --benchmark truthfulqa --batch-size 5
#
# Full benchmark:
#   python trilogy_app.py --benchmark truthfulqa
#
# Results location:
#   Results/[model-name]/truthfulqa_results.csv
#   Results/[model-name]/truthfulqa_summary.json
#
# For more info: Documentation/SETUP.md
