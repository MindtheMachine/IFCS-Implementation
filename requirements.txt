# ============================================================================
# Core Dependencies (REQUIRED)
# ============================================================================
# These are always needed for the trilogy system to function

# Environment variable loading from .env files (REQUIRED)
python-dotenv>=1.0.0

# Anthropic API client (default LLM provider)
anthropic>=0.40.0

# Web interface
gradio>=4.0.0

# Core computational libraries
numpy>=1.24.0

# ============================================================================
# Benchmark Evaluation Dependencies (REQUIRED for benchmarks)
# ============================================================================
# Install these to run TruthfulQA and ASQA benchmarks

# HuggingFace datasets library (loads TruthfulQA, ASQA)
datasets>=2.14.0

# ROUGE metrics for ASQA evaluation
rouge-score>=0.1.2

# Progress bars for batch processing
tqdm>=4.66.0

# Data manipulation and CSV generation
pandas>=2.0.0

# ============================================================================
# ECR Experiment Dependencies (REQUIRED for empirical validation)
# ============================================================================
# These are needed to run the ECR comparison experiments

# Statistical analysis (t-tests, ANOVA, etc.)
scipy>=1.11.0

# Machine learning utilities (clustering, metrics)
scikit-learn>=1.3.0

# Semantic similarity for self-consistency baseline
sentence-transformers>=2.2.0

# ============================================================================
# Alternative LLM Providers (REQUIRED - Install all for full compatibility)
# ============================================================================
# All providers are now included by default for better user experience

# OpenAI API (for GPT-4, GPT-3.5-turbo, etc.)
openai>=1.0.0

# HuggingFace Inference API (for Llama, Mistral, etc.)
huggingface-hub>=0.20.0

# Ollama (for local models)
ollama>=0.1.0

# ============================================================================
# Configuration File Support (OPTIONAL)
# ============================================================================
# YAML configuration file support (trilogy_config.yaml)
# Uncomment if you want to use YAML config files instead of JSON
# pyyaml>=6.0.1

# ============================================================================
# Development Dependencies (REQUIRED for testing)
# ============================================================================
# Testing framework and property-based testing

pytest>=7.4.0              # Testing framework (REQUIRED for commitment-actuality gate tests)
hypothesis>=6.0.0          # Property-based testing framework (REQUIRED)

# Optional development tools (uncomment if needed)
# black>=23.0.0              # Code formatting
# flake8>=6.0.0              # Linting
# mypy>=1.5.0                # Type checking

# ============================================================================
# Installation Instructions
# ============================================================================
#
# BASIC INSTALLATION (All providers included):
#   pip install -r requirements.txt
#
# QUICK SETUP:
#   1. pip install -r requirements.txt
#   2. Copy .env.template to .env
#   3. Configure your preferred provider in .env:
#      - For Anthropic Claude: Set LLM_PROVIDER=anthropic, add API key
#      - For OpenAI GPT: Set LLM_PROVIDER=openai, add API key  
#      - For HuggingFace: Set LLM_PROVIDER=huggingface, add token
#      - For Ollama (local): Set LLM_PROVIDER=ollama, no API key needed
#
# OLLAMA SETUP (Local models - FREE):
#   1. Download Ollama from https://ollama.com/
#   2. Run: ollama pull mistral (or llama3.1, phi3, etc.)
#   3. Set in .env: LLM_PROVIDER=ollama, LLM_MODEL=mistral
#   4. No API key needed!
#
# HUGGINGFACE FREE TIER:
#   1. Get FREE token from: https://huggingface.co/settings/tokens
#   2. Set in .env: LLM_PROVIDER=huggingface, LLM_API_KEY=your_token
#   3. Use smaller batches: --batch-size 5 --rate-limit 2.0
#
# WITH YAML CONFIG SUPPORT:
#   1. Uncomment: pyyaml>=6.0.1
#   2. Run: pip install -r requirements.txt
#   3. Create: trilogy_config.yaml
#
# ============================================================================
# Upgrade All Packages
# ============================================================================
# To upgrade all packages to latest versions:
#   pip install --upgrade -r requirements.txt
#
# ============================================================================
